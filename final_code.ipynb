{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "BASE_DIR = Path(\"/Users/sp7078/Downloads/Kaggle_Data\")\n",
    "TRAIN_CSV = BASE_DIR / \"metadata\" / \"kaggle_train.csv\"\n",
    "TEST_CSV = BASE_DIR / \"metadata\" / \"kaggle_test.csv\"\n",
    "AUDIO_DIR = BASE_DIR / \"audio\"\n",
    "TEST_AUDIO_DIR = AUDIO_DIR / \"test\"\n",
    "FINAL_PATH = \"audio_final_cnn.pth\"\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "CLIP_DURATION = 4.0\n",
    "SIGNAL_LENGTH = int(SAMPLE_RATE * CLIP_DURATION)\n",
    "\n",
    "N_MELS = 64\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 1e-3\n",
    "VAL_RATIO = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    import torch, random, numpy as np\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def load_audio(path):\n",
    "    y, sr = librosa.load(path, sr=SAMPLE_RATE, mono=True)\n",
    "    return y\n",
    "\n",
    "\n",
    "def fix_length(y):\n",
    "    if len(y) < SIGNAL_LENGTH:\n",
    "        pad = SIGNAL_LENGTH - len(y)\n",
    "        y = np.pad(y, (0, pad))\n",
    "    elif len(y) > SIGNAL_LENGTH:\n",
    "        start = (len(y) - SIGNAL_LENGTH) // 2\n",
    "        y = y[start:start + SIGNAL_LENGTH]\n",
    "    return y\n",
    "\n",
    "\n",
    "def mk_logmel(y):\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=y,\n",
    "        sr=SAMPLE_RATE,\n",
    "        n_fft=N_FFT,\n",
    "        hop_length=HOP_LENGTH,\n",
    "        n_mels=N_MELS,\n",
    "        power=2.0\n",
    "    )\n",
    "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "    mel_db = (mel_db - mel_db.mean()) / (mel_db.std() + 1e-9)\n",
    "    return mel_db.astype(np.float32)\n",
    "\n",
    "import random\n",
    "\n",
    "def spec_augment(mel, max_mask_pct=0.15, num_freq_masks=2, num_time_masks=2):\n",
    "    n_mels, n_steps = mel.shape\n",
    "    mask_val = mel.mean()\n",
    "\n",
    "    for _ in range(num_freq_masks):\n",
    "        f = random.randint(0, int(max_mask_pct * n_mels))\n",
    "        f0 = random.randint(0, n_mels - f)\n",
    "        mel[f0:f0+f, :] = mask_val\n",
    "\n",
    "    for _ in range(num_time_masks):\n",
    "        t = random.randint(0, int(max_mask_pct * n_steps))\n",
    "        t0 = random.randint(0, n_steps - t)\n",
    "        mel[:, t0:t0+t] = mask_val\n",
    "    \n",
    "    return mel\n",
    "\n",
    "\n",
    "def mixup(x, y, alpha=0.4):\n",
    "    l = np.random.beta(alpha, alpha)\n",
    "    idx = torch.randperm(x.size(0))\n",
    "    x2, y2 = x[idx], y[idx]\n",
    "    x_mix = l * x + (1 - l) * x2\n",
    "    return x_mix, y, y2, l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoundDataset(Dataset):\n",
    "    def __init__(self, df, audio_root, train=True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.audio_root = audio_root\n",
    "        self.train = train\n",
    "\n",
    "        uniq_labels = sorted(df[\"class\"].unique())\n",
    "        self.label2id = {lab: i for i, lab in enumerate(uniq_labels)}\n",
    "        self.id2label = {v: k for k, v in self.label2id.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def find_audio(self, filename):\n",
    "        for d in self.audio_root.glob(\"fold*\"):\n",
    "            candidate = d / filename\n",
    "            if candidate.exists():\n",
    "                return candidate\n",
    "        raise FileNotFoundError(f\"Not found in any fold: {filename}\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        filename = row[\"slice_file_name\"]\n",
    "        label = row[\"class\"]\n",
    "\n",
    "        path = self.find_audio(filename) \n",
    "        y = load_audio(path)\n",
    "        y = fix_length(y)\n",
    "        mel = mk_logmel(y)\n",
    "\n",
    "        if self.train:\n",
    "            mel=spec_augment(mel)\n",
    "\n",
    "        mel_tensor = torch.tensor(mel).unsqueeze(0)\n",
    "        return mel_tensor, self.label2id[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=2),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=2),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class AudioCNN(nn.Module):\n",
    "    def __init__(self, class_num):\n",
    "        super().__init__()\n",
    "        self.b1 = ConvBlock(1, 32)\n",
    "        self.b2 = ConvBlock(32, 64)\n",
    "        self.b3 = ConvBlock(64, 128)\n",
    "        self.b4 = ConvBlock(128, 256)\n",
    "        self.b5= ConvBlock(256,512)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, class_num)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.b1(x)\n",
    "        x = self.b2(x)\n",
    "        x = self.b3(x)\n",
    "        x = self.b4(x)\n",
    "        x=self.b5(x)\n",
    "        \n",
    "        \n",
    "        x = x.mean(dim=(-1, -2))  # GAP\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_epoch(model, loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    pbar = tqdm(loader, desc=\"TRAIN\", leave=False)\n",
    "    for mel, label in pbar:\n",
    "        mel, label = mel.to(device), label.to(device)\n",
    "        mel, label = mel.to(device), label.to(device)\n",
    "        mel, label_orig, label_shuf, lam = mixup(mel, label)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(mel)\n",
    "        loss = lam * loss_fn(logits, label_orig) + (1-lam) * loss_fn(logits, label_shuf)\n",
    "\n",
    "\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        pred = logits.argmax(1)\n",
    "        correct += (pred == label).sum().item()\n",
    "        total += label.size(0)\n",
    "\n",
    "        pbar.set_postfix(loss=f\"{running_loss/len(loader):.4f}\",\n",
    "                         acc=f\"{correct/total:.4f}\")\n",
    "\n",
    "    avg_loss = running_loss / len(loader)\n",
    "    avg_acc = correct / total\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "\n",
    "\n",
    "def validate(model, loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc=\"VAL\", leave=False)\n",
    "        for mel, label in pbar:\n",
    "            mel, label = mel.to(device), label.to(device)\n",
    "\n",
    "            logits = model(mel)\n",
    "            loss = loss_fn(logits, label)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            pred = logits.argmax(1)\n",
    "            correct += (pred == label).sum().item()\n",
    "            total += label.size(0)\n",
    "\n",
    "            pbar.set_postfix(loss=f\"{running_loss/len(loader):.4f}\",\n",
    "                             acc=f\"{correct/total:.4f}\")\n",
    "\n",
    "    avg_loss = running_loss / len(loader)\n",
    "    avg_acc = correct / total\n",
    "    return avg_loss, avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    set_seed(42)\n",
    "\n",
    "    df = pd.read_csv(TRAIN_CSV)\n",
    "\n",
    "    df_train = df[df[\"fold\"] <= 7]\n",
    "    df_val   = df[df[\"fold\"] > 7]\n",
    "\n",
    "    train_data = SoundDataset(df_train, AUDIO_DIR, train=True)\n",
    "    val_data   = SoundDataset(df_val, AUDIO_DIR, train=False)\n",
    "\n",
    "    train_load = DataLoader(train_data, batch_size=16, shuffle=True, num_workers=0)\n",
    "    val_load   = DataLoader(val_data, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model = AudioCNN(class_num=10).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=8)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    epochs = 50\n",
    "    best_val_acc = 0.0\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEPOCH {epoch + 1} / {epochs}\")\n",
    "\n",
    "        train_loss, train_acc = train_epoch(model, train_load, optimizer, loss_fn, device)\n",
    "        val_loss, val_acc     = validate(model, val_load, loss_fn, device)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val   Loss: {val_loss:.4f}, Val   Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_state = model.state_dict()\n",
    "            print(f\"New best val_acc={best_val_acc:.4f}\")\n",
    "\n",
    "    if best_state is not None:\n",
    "        torch.save(best_state, FINAL_PATH)\n",
    "        print(f\"\\nSaved best model with val_acc={best_val_acc:.4f} to {FINAL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    df_test = pd.read_csv(TEST_CSV)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    \n",
    "    model = AudioCNN(class_num=10).to(device)\n",
    "    model.load_state_dict(torch.load(FINAL_PATH, map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "\n",
    "    ids=[]\n",
    "    preds=[]\n",
    "\n",
    "\n",
    "    results = []\n",
    "    for i, row in tqdm(df_test.iterrows(), total=len(df_test)):\n",
    "        fname=row[\"slice_file_name\"]\n",
    "        ID=row[\"ID\"]\n",
    "        path = TEST_AUDIO_DIR / fname\n",
    "\n",
    "        y = load_audio(path)\n",
    "        y = fix_length(y)\n",
    "        mel = mk_logmel(y)\n",
    "        x = torch.tensor(mel).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(x).argmax(1).item()\n",
    "\n",
    "        ids.append(ID)\n",
    "        preds.append(pred)\n",
    "\n",
    "    df_sub = pd.DataFrame({\"ID\": ids, \"TARGET\": preds})\n",
    "    df_sub.to_csv(\"submission_new.csv\", index=False)\n",
    "    print(\"submission_new.csv saved.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #main()\n",
    "    predict()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
